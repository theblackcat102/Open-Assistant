"use strict";(self.webpackChunkopen_assistant=self.webpackChunkopen_assistant||[]).push([[8475],{3905:(e,t,n)=>{n.d(t,{Zo:()=>c,kt:()=>u});var i=n(67294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);t&&(i=i.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,i)}return n}function s(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function o(e,t){if(null==e)return{};var n,i,a=function(e,t){if(null==e)return{};var n,i,a={},r=Object.keys(e);for(i=0;i<r.length;i++)n=r[i],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(i=0;i<r.length;i++)n=r[i],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var l=i.createContext({}),p=function(e){var t=i.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):s(s({},t),e)),n},c=function(e){var t=p(e.components);return i.createElement(l.Provider,{value:t},e.children)},h="mdxType",d={inlineCode:"code",wrapper:function(e){var t=e.children;return i.createElement(i.Fragment,{},t)}},m=i.forwardRef((function(e,t){var n=e.components,a=e.mdxType,r=e.originalType,l=e.parentName,c=o(e,["components","mdxType","originalType","parentName"]),h=p(n),m=a,u=h["".concat(l,".").concat(m)]||h[m]||d[m]||r;return n?i.createElement(u,s(s({ref:t},c),{},{components:n})):i.createElement(u,s({ref:t},c))}));function u(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var r=n.length,s=new Array(r);s[0]=m;var o={};for(var l in t)hasOwnProperty.call(t,l)&&(o[l]=t[l]);o.originalType=e,o[h]="string"==typeof e?e:a,s[1]=o;for(var p=2;p<r;p++)s[p]=n[p];return i.createElement.apply(null,s)}return i.createElement.apply(null,n)}m.displayName="MDXCreateElement"},50887:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>o,toc:()=>p});var i=n(87462),a=(n(67294),n(3905));const r={},s="Inference",o={unversionedId:"architecture/inference",id:"architecture/inference",title:"Inference",description:"From the perspective of the Text Client",source:"@site/docs/architecture/inference.md",sourceDirName:"architecture",slug:"/architecture/inference",permalink:"/Open-Assistant/docs/architecture/inference",draft:!1,tags:[],version:"current",frontMatter:{},sidebar:"sidebar",previous:{title:"Architecture",permalink:"/Open-Assistant/docs/architecture/"},next:{title:"Inference",permalink:"/Open-Assistant/docs/architecture/inference"}},l={},p=[{value:"From the perspective of the Text Client",id:"from-the-perspective-of-the-text-client",level:3},{value:"From the perspective of the OA Inference Server",id:"from-the-perspective-of-the-oa-inference-server",level:3},{value:"From the perspective of the OA Worker",id:"from-the-perspective-of-the-oa-worker",level:3}],c={toc:p},h="wrapper";function d(e){let{components:t,...n}=e;return(0,a.kt)(h,(0,i.Z)({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"inference"},"Inference"),(0,a.kt)("h3",{id:"from-the-perspective-of-the-text-client"},"From the perspective of the Text Client"),(0,a.kt)("mermaid",{value:'---\ntitle: Overview of Text Client Workflow\n---\ngraph LR;\n    subgraph OA Server\n    /auth/callback/debug\n    id0["/chats"]\n    id1["/chats/{chat_id}/messages"]\n    id2["{backend_url}/chats/{chat_id}/messages/{message_id}/events"]\n    end\n\n    subgraph text-client\n    id3["SSEClient(response)"]\n    end\n\n    text-client == 1. GET ==> /auth/callback/debug;\n    /auth/callback/debug -- bearer_token --\x3e text-client;\n\n    text-client == 2. POST ==> id0["/chats"]\n    id0["/chats"] -- chat_id --\x3e text-client;\n\n    text-client == 3. requests prompt ==> user;\n    user == submits prompt ==> text-client;\n\n    text-client == 4. POST ==> id1["/chats/{chat_id}/messages"];\n    id1["/chats/{chat_id}/messages"] -- message_id --\x3e text-client;\n\n    text-client == 5. GET ==> id2["{backend_url}/chats/{chat_id}/messages/{message_id}/events"];\n    id2["{backend_url}/chats/{chat_id}/messages/{message_id}/events"] -- events --\x3e id3["SSEClient(response)"];\n\n    linkStyle 0 stroke-width:2px,fill:none,stroke:green;\n    linkStyle 1 stroke-width:2px,fill:none,stroke:green;\n    linkStyle 2 stroke-width:2px,fill:none,stroke:purple;\n    linkStyle 3 stroke-width:2px,fill:none,stroke:purple;\n    linkStyle 4 stroke-width:2px,fill:none,stroke:blue;\n    linkStyle 5 stroke-width:2px,fill:none,stroke:blue;\n    linkStyle 6 stroke-width:2px,fill:none,stroke:grey;\n    linkStyle 7 stroke-width:2px,fill:none,stroke:grey;'}),(0,a.kt)("p",null,"For development, a basic REPL client is used as a chat interface, built around\n",(0,a.kt)("a",{parentName:"p",href:"https://typer.tiangolo.com/"},"Typer"),". The bulk of the logic is in\n",(0,a.kt)("inlineCode",{parentName:"p"},"inference.text-client.text_client_utils.DebugClient"),". The basic steps are as\nfollows:"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"The debug client first authenticates with a GET request to\n",(0,a.kt)("inlineCode",{parentName:"p"},"/auth/callback/debug")," which returns a bearer token, which is then set in\nfuture request headers.")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"After authenticating, the ",(0,a.kt)("inlineCode",{parentName:"p"},"DebugClient"),' creates a "chat" by posting to\n',(0,a.kt)("inlineCode",{parentName:"p"},"/chats"),", which returns a ",(0,a.kt)("inlineCode",{parentName:"p"},"chat_id")," for session.")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"The script then collects the user prompt.")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"The ",(0,a.kt)("inlineCode",{parentName:"p"},"DebugClient")," posts to the endpoint ",(0,a.kt)("inlineCode",{parentName:"p"},"/chats/{chat_id}/messages"),". Included\nin this request is the message content, a ",(0,a.kt)("inlineCode",{parentName:"p"},"parent_id:str")," (ID of assistant's\nresponse to prior message, if there is one), the ",(0,a.kt)("inlineCode",{parentName:"p"},"model_config_name:str"),", and\ninference ",(0,a.kt)("inlineCode",{parentName:"p"},"sampling_parameters:dict"),". In the response, the server will return\na ",(0,a.kt)("inlineCode",{parentName:"p"},"message_id:str"),".")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"The client will use this id to make a GET request to\n",(0,a.kt)("inlineCode",{parentName:"p"},"{backend_url}/chats/{chat_id}/messages/{message_id}/events"),". Critically, in\nthis ",(0,a.kt)("inlineCode",{parentName:"p"},"get()")," method of requests, the ",(0,a.kt)("inlineCode",{parentName:"p"},"stream=True")," is passed, meaning that\nthe response content will not be immediately downloaded but rather streamed.\nAdditionally, the actual GET request must have\n",(0,a.kt)("inlineCode",{parentName:"p"},'"Accept": "text/event-stream"')," in the headers to let the server know we are\nawaiting an event stream.")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"The response is then used to instantiate an SSEClient, which - via its\nevents() method, returns an iterable that can be used to print out inference\nresults, one token at a time.")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"After exhausting the events iterable (ie inference is complete), the user is\nprompted for a new message."))),(0,a.kt)("h3",{id:"from-the-perspective-of-the-oa-inference-server"},"From the perspective of the OA Inference Server"),(0,a.kt)("p",null,"The inference server is built around ",(0,a.kt)("a",{parentName:"p",href:"https://fastapi.tiangolo.com/"},"FastAPI"),"."),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"When the client posts to ",(0,a.kt)("inlineCode",{parentName:"p"},"/chats"),", the UserChatRepository - an interface\nbetween application logic and chats message tables - creates a chat in the\nchat table, which assigns the needed chat id and is returned in the response\nto the client.")),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"Next, the client POSTs to ",(0,a.kt)("inlineCode",{parentName:"p"},"/chats/{chat_id}/prompter_message"),", which uses the\n",(0,a.kt)("inlineCode",{parentName:"p"},"UserChatRepository")," to:"),(0,a.kt)("ol",{parentName:"li"},(0,a.kt)("li",{parentName:"ol"},"Check to see if the message content included in the POST request is longer\nthan the configured settings."),(0,a.kt)("li",{parentName:"ol"},"Using the database session and ",(0,a.kt)("inlineCode",{parentName:"li"},"user_id")," which was configured when this\ninstance of ",(0,a.kt)("inlineCode",{parentName:"li"},"UserChatRepository")," was instantiated, we lookup in the ",(0,a.kt)("inlineCode",{parentName:"li"},"chat"),"\ntable the corresponding entry for this ",(0,a.kt)("inlineCode",{parentName:"li"},"chat_id")," and ",(0,a.kt)("inlineCode",{parentName:"li"},"user_id"),"."),(0,a.kt)("li",{parentName:"ol"},"Check to see if the total number of assistant + prompter messages in the\n",(0,a.kt)("inlineCode",{parentName:"li"},"chat")," is greater than the configured settings."),(0,a.kt)("li",{parentName:"ol"},"If this is a new chat (i.e. no ",(0,a.kt)("inlineCode",{parentName:"li"},"parent_id")," is set in the ",(0,a.kt)("inlineCode",{parentName:"li"},"chat"),"), and the\nchat table contains no title for chat of that id, updates the chat table\nwith the initial user prompt as title."),(0,a.kt)("li",{parentName:"ol"},"Creates a message in the message table for the user prompt."))),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"The client then POSTs to ",(0,a.kt)("inlineCode",{parentName:"p"},"/chats/{chat_id}/assistant_message"),"."),(0,a.kt)("ol",{parentName:"li"},(0,a.kt)("li",{parentName:"ol"},"First we load the model config for the ",(0,a.kt)("inlineCode",{parentName:"li"},"model_config_name")," specified by\nthe client's request."),(0,a.kt)("li",{parentName:"ol"},"Then, we use the ",(0,a.kt)("inlineCode",{parentName:"li"},"UserChatRepository")," to post to create a message in the\n",(0,a.kt)("inlineCode",{parentName:"li"},"message")," table, with a pending state. Note, we also will update the state\nfor any other currently pending messages in the chat to\n",(0,a.kt)("inlineCode",{parentName:"li"},"inference.MessageState.cancelled"),"."),(0,a.kt)("li",{parentName:"ol"},"After updating the ",(0,a.kt)("inlineCode",{parentName:"li"},"message")," table, we create a RedisQueue for this\nspecific message and enque the message."),(0,a.kt)("li",{parentName:"ol"},"Finally, we return an ",(0,a.kt)("inlineCode",{parentName:"li"},"inference.MessageRead")," (a Pydantic model) to the\nclient. This is the object contains the needed ",(0,a.kt)("inlineCode",{parentName:"li"},"message_id"),"."))),(0,a.kt)("li",{parentName:"ol"},(0,a.kt)("p",{parentName:"li"},"Once the client has the ",(0,a.kt)("inlineCode",{parentName:"p"},"message_id"),", it will make a GET request to\n",(0,a.kt)("inlineCode",{parentName:"p"},"/chats/{chat_id}/messages/{message_id}/events"),". Upon receiving this request,\nthe server retrieves the message from the message table and verifies that the\nmessage isn't finished and that the message role is assistant."))),(0,a.kt)("p",null,"After this, we get the Redis queue for this specific message id. From here, we\npoll the queue, using the ",(0,a.kt)("inlineCode",{parentName:"p"},"dequeue()")," method. By default this method will block\nfor up to 1 second, however if a message is added to the queue in that interval,\nit will automatically be returned. Otherwise, ",(0,a.kt)("inlineCode",{parentName:"p"},"dequeue()")," will return ",(0,a.kt)("inlineCode",{parentName:"p"},"None"),"."),(0,a.kt)("p",null,"If ",(0,a.kt)("inlineCode",{parentName:"p"},"None")," is returned and this is the first time we have polled the queue since\nits creation, we will yield a ",(0,a.kt)("inlineCode",{parentName:"p"},"chat_schema.PendingResponseEvent"),". The loop will\ncontinue, with 1 second blocking (by default), until a message item is returned.\nA message item is a tuple where the first element is a string of the message id,\nand the second element is a response. After some checks on the message response\ntype (for example if there is a safety intervention or an internal error from\nthe worker), we yield a ",(0,a.kt)("inlineCode",{parentName:"p"},"chat_schema.MessageResponseEvent"),". The message polling\nand yielding is bundled in an ",(0,a.kt)("inlineCode",{parentName:"p"},"EventSourceResponse")," object."),(0,a.kt)("p",null,"The EventSourceResponse is Server Sent Events (SSE) plugin for\nStarlette/FastAPI, which takes content and returns it as part of a HTTP event\nstream. You can check out the EventSourceResposethe library's\n",(0,a.kt)("a",{parentName:"p",href:"https://github.com/sysid/sse-starlette/tree/master"},"source code")," for more\ndetails about how this works."),(0,a.kt)("h3",{id:"from-the-perspective-of-the-oa-worker"},"From the perspective of the OA Worker"),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"This section is not yet written"),". If you are interested in helping write it\nplease get in touch on GitHub or Discord."))}d.isMDXComponent=!0}}]);